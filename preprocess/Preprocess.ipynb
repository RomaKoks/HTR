{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76df605d-49e7-4145-94eb-be9b7c955485",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1196338f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5111817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mpl.rc('figure',figsize=(5, 20))\n",
    "mpl.rc('xtick', labelsize=16) \n",
    "mpl.rc('ytick', labelsize=16)\n",
    "mpl.rc('font', size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c532ef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json, os, glob, string\n",
    "\n",
    "from time import time\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f048ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ann_path = os.path.join('..', 'HKR_Dataset_Words_Public', 'ann')\n",
    "img_path = os.path.join('..', 'HKR_Dataset_Words_Public', 'img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c2d171d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_image(path: str, ax: matplotlib.axes._subplots.Axes,\n",
    "               title: str='', img_path: str=img_path) -> None:\n",
    "\n",
    "    '''Utility fiunction for printing images from \"path\"'''\n",
    "\n",
    "    image = io.imread(os.path.join(img_path, path))\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.axis(\"off\")\n",
    "    title = title if title else path\n",
    "    ax.set_title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3342325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def counts_to_df(df: pd.DataFrame, column: str='description') -> pd.DataFrame:\n",
    "    \n",
    "    '''Return dataframe with symbols counts from \"column\"'''\n",
    "\n",
    "    counts = pd.DataFrame(df[column].map(list).explode())\n",
    "    counts = counts.join(counts[column].value_counts(), on=column, rsuffix='1')\n",
    "    counts.columns = ['symbols', 'counts']\n",
    "    counts = counts[~(counts.symbols == '') & ~(counts.symbols == ' ')]  #.drop_duplicates()\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b297ad72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 16371/64943 [05:17<15:43, 51.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7df63151dd46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'execution time:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'secs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmeta_collect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metadata.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metadata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metadata.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7df63151dd46>\u001b[0m in \u001b[0;36mmeta_collect\u001b[0;34m(ann_path, result_file, sep)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, errors)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mbyte\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \"\"\"\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0mIncrementalDecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;31m# undecoded input that is kept between calls to decode()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def meta_collect(ann_path: str, result_file: str, sep: str='\\t') -> None:\n",
    "    \n",
    "    '''collect metadata for all images to \"result_file\"\n",
    "    from json files in \"ann_path\" (execution time: about 5 mins)'''\n",
    "\n",
    "    start = time()\n",
    "    with open(result_file, 'w',  encoding='utf-8') as f:\n",
    "        f.write(sep.join(['width', 'height', 'description',\n",
    "                           'isModerated', 'moderatedBy', 'predicted']) + '\\n')\n",
    "\n",
    "    \n",
    "        for file in tqdm(glob.glob(os.path.join(ann_path, '*.json'))):\n",
    "\n",
    "            with open(file, encoding='utf-8') as js:\n",
    "                tmp = json.load(js)\n",
    "\n",
    "            try:\n",
    "                f.write(sep.join([tmp['name'], str(tmp['size']['width']), str(tmp['size']['height']),\n",
    "                               tmp['description'], str(tmp['moderation']['isModerated']),\n",
    "                               tmp['moderation']['moderatedBy'], str(tmp['moderation']['predicted'])]) + '\\n')\n",
    "            except Exception:\n",
    "                print(tmp['description'])\n",
    "    print('execution time:', (time() - start), 'secs')\n",
    "\n",
    "meta_collect(ann_path, 'metadata.tsv')\n",
    "df = pd.read_csv(os.path.join('..', 'metadata', 'metadata.tsv'), sep='\\t', index_col=0)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0c4cc-9a86-42dd-ade1-cdd4289fda09",
   "metadata": {},
   "source": [
    "# EDA with some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5d0a72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9c76c4-626f-407f-9e1a-e128fd8528ff",
   "metadata": {},
   "source": [
    "### Drop useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672bdbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[~df.predicted.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36ee16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isModerated.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b2306",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(['predicted', 'isModerated'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a196b7dd-b5a9-440c-8e7c-984e8312426d",
   "metadata": {},
   "source": [
    "### Moderator - useless or not? (need help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c901c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cou = df.moderatedBy.value_counts()\n",
    "cou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e473c4-51c0-448a-8ee1-f9738dd213dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cou[1] / (cou[0] + cou[1]) # ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba5aad4-c89f-4e68-ac2d-d113d572827c",
   "metadata": {},
   "source": [
    "### Some random pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d611a20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "img_names = random.choice(df.index, n)\n",
    "fig, axes = subplots(n, 1)\n",
    "\n",
    "for img_name, ax in zip(img_names, axes):\n",
    "    read_image(img_name + '.jpg', ax=ax, title=img_name + f'  ({df.loc[img_name].description})')\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c03b983-7134-4ed9-a1f4-1ed3d91ec4ac",
   "metadata": {},
   "source": [
    "### Dataset symbol counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb1ef3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating dataframe with symbol counts with indexes from original df\n",
    "counts = counts_to_df(df, 'description')\n",
    "\n",
    "# Barplot with symbol counts in dataset\n",
    "fig, ax = subplots(figsize=(20, 10))\n",
    "sns.barplot(data=counts.sort_values('counts', ascending=False), x='symbols', y='counts', ax=ax)\n",
    "\n",
    "tight_layout()\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5d0d44-594d-4acf-b5b1-71273841f2cc",
   "metadata": {},
   "source": [
    "### Find all non-ordinary symbols for Russian language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01149795",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating reference alphabet with Russian (lower- and uppercase) and punctuation symbols\n",
    "alphabet_lower = [chr(ord(\"а\") + i) for i in range(32)] + [chr(ord(\"а\") + 33)] # Last is \"ё\"\n",
    "alphabet_upper = [chr(ord(\"А\") + i) for i in range(32)]\n",
    "punctuation = list(string.punctuation)\n",
    "\n",
    "alphabet = set(alphabet_lower + alphabet_upper + punctuation)\n",
    "\n",
    "# Creating alphabet from dataset\n",
    "counts_dict = counts.set_index('symbols')['counts'].to_dict()\n",
    "\n",
    "# difference between dataset and reference alphabet\n",
    "smth_symbols = set(counts_dict) - alphabet \n",
    "smth_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa8fd0-9172-4adb-9537-468d040978b7",
   "metadata": {},
   "source": [
    "### Plotting the non-reference symbols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9724ec5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = subplots(len(smth_symbols), 1)\n",
    "\n",
    "for sym, ax in zip(smth_symbols, axes):\n",
    "    ind = counts[counts.symbols == sym].index[0]\n",
    "    read_image(ind + '.jpg', ax, df.loc[ind].description + f'    ({sym})')\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7ac17a-7a97-4d0b-b2be-750cab982ba5",
   "metadata": {},
   "source": [
    "### Rows with non-reference symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e9488a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "df.loc[counts[counts.symbols.isin(smth_symbols)].index.drop_duplicates()].drop_duplicates('description')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f94ef1b-c524-4c96-9b1b-1b46587851fe",
   "metadata": {},
   "source": [
    "### Some Russian symbols are in latin spelling and some punctuation symbols are not in unicode format, so rework a part of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3411a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.description = df.description.str.replace('o', 'о').str.replace('H', 'Н')\n",
    "df.description = df.description.str.replace('–', '-').str.replace('—', '-').str.replace('…', '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734697c-cd9d-4eb2-93c9-518104632542",
   "metadata": {},
   "source": [
    "### The remaining non-Russian and non-punctuation symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e25e98c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts = counts_to_df(df, 'description')\n",
    "\n",
    "counts_dict = counts.set_index('symbols')['counts'].to_dict()\n",
    "kazakh_symbols = set(counts_dict) - alphabet\n",
    "kazakh_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ffa10-fabc-4445-80bf-4be22f01b36c",
   "metadata": {},
   "source": [
    "### Drop remaining non-reference symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b841efd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"rows to drop:\", df.loc[counts[counts.symbols.isin(kazakh_symbols)].index.drop_duplicates()].shape[0])\n",
    "df = df.drop(counts[counts.symbols.isin(kazakh_symbols)].index.drop_duplicates(), axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a6fdb",
   "metadata": {},
   "source": [
    "### Сomparison between the frequency of letters in the Russian alphabet ([ref link](https://ru.wikipedia.org/wiki/%D0%A7%D0%B0%D1%81%D1%82%D0%BE%D1%82%D0%BD%D0%BE%D1%81%D1%82%D1%8C)) and in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b6e398",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = subplots(2, 1, figsize=(15, 15))\n",
    "\n",
    "tmp = counts_to_df(df)\n",
    "tmp = tmp[~tmp.symbols.isin(punctuation)].drop_duplicates('symbols')\n",
    "\n",
    "dictir = {}\n",
    "for i, j in tmp.iterrows():\n",
    "    sym, cou = j\n",
    "    dictir[sym.lower()] = dictir.get(sym.lower(), 0) + cou\n",
    "tmp = pd.DataFrame(dictir, index=['counts']\n",
    "                  ).T.reset_index().sort_values('counts', ascending=False)\n",
    "\n",
    "sns.barplot(data=tmp, x='index', y='counts', ax=axes[0])\n",
    "axes[0].set_title('Dataset alphabet')\n",
    "\n",
    "ls = pd.read_csv(os.path.join('..', 'metadata', 'alphabet.tsv'), sep='\\t', \n",
    "                 index_col=1).sort_values('Частотность', ascending=False)\n",
    "sns.barplot(data=ls, x='Буква', y='Частотность', ax=axes[1])\n",
    "axes[1].set_title('Russian alphabet')\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005382df-e3c3-475a-bad3-49433d8462b9",
   "metadata": {},
   "source": [
    "### Label counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66edeca8-5d8d-4eb6-8e07-37236bed5bb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.description.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a330d-84b9-4df7-b111-dd1fce6274bd",
   "metadata": {},
   "source": [
    "### Pictures sizes description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eed0be-0f38-49b0-b2d9-50d60293fd9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"width: max = {df.width.max()}, min = {df.width.min()}, mean = {df.width.mean()}\")\n",
    "print(f\"height: max = {df.height.max()}, min = {df.height.min()}, mean = {df.height.mean()}\\n\")\n",
    "\n",
    "mheight = df.height.value_counts().sort_values(ascending=False)\n",
    "mwidth = df.width.value_counts().sort_values(ascending=False)\n",
    "\n",
    "print(f'most common widths (of {mwidth.shape[0]} size):\\nwidth\\tcount\\n{mwidth.head(10)}\\nand their mean = {mwidth.head(10).index.to_series().mean()}\\n')\n",
    "print(f'most common heights (of {mheight.shape[0]} size):\\nheight\\tcount\\n{mheight.head(10)}\\nand their mean = {mheight.head(10).index.to_series().mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f082c4c-7cc8-492f-a2ce-4a57aa0c9ef9",
   "metadata": {},
   "source": [
    "### Most common size values pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54900f8-0cd7-4fca-b95a-f4d794392b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = subplots(4, 1, figsize=(10, 15))\n",
    "\n",
    "df_list = [df[df.height == mheight.index[0]],\n",
    "           df[df.height == mheight.index[-1]],\n",
    "           df[df.width == mwidth.index[0]],\n",
    "           df[df.width == mwidth.index[-1]]]\n",
    "\n",
    "titles = ['most common height example',\n",
    "          'least common height example',\n",
    "          'most common width example',\n",
    "          'least common width example']\n",
    "\n",
    "for tmp, title, ax in zip(df_list, titles, axes):\n",
    "    read_image(tmp.index[0] + '.jpg', ax, title=title + f' ({tmp.description[0]})')\n",
    "    ax.axis('on')\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c6a75a-8df9-4434-9efb-5c58352a7922",
   "metadata": {},
   "source": [
    "### Extreme size values pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021a9b8-4c90-4c7e-9a9b-4f0d034ca090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = subplots(6, 1, figsize=(10, 15))\n",
    "\n",
    "df_list = [df[df.height == df.height.max()],\n",
    "           df[df.height == df.height.min()],\n",
    "           df[df.width == df.width.max()],\n",
    "           df[df.width == df.width.min()],\n",
    "           df[df.description.apply(len) == df.description.apply(len).max()],\n",
    "           df[df.description.apply(len) == df.description.apply(len).min()]]\n",
    "\n",
    "titles = ['max hight example',\n",
    "          'min hight example',\n",
    "          'max width example',\n",
    "          'min width example',\n",
    "          'max len description',\n",
    "          'min len description']\n",
    "\n",
    "for tmp, title, ax in zip(df_list, titles, axes):\n",
    "    read_image(tmp.index[0] + '.jpg', ax, title=title + f' ({tmp.description[0]})')\n",
    "    ax.axis('on')\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b28949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_height, img_width = 100, 600\n",
    "df = df[(df.width <= img_width) & (df.height <= img_height)]\n",
    "max_length = df.description.str.len().max()\n",
    "print(max_length)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afadbbd-8300-470d-8261-9c6d65d3bd79",
   "metadata": {},
   "source": [
    "# Train test val split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163efdc-9937-41a0-81e9-4cc78f4cd878",
   "metadata": {},
   "source": [
    "### Get utility dataframe with rows as picture names and columns as all symbols that presented in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db87228a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# There is 1.0 in cell if there is this symbol in this picture otherwise 0 \n",
    "counts = counts_to_df(df, 'description')\n",
    "counts.counts = 1\n",
    "splitter = counts.reset_index().drop_duplicates().pivot(index='index', columns='symbols').fillna(0)\n",
    "splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037c7e8-f88a-4706-84e8-82fe867c02a5",
   "metadata": {},
   "source": [
    "### split into three dataframes (train 85%, test 10%, val 5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa923fa5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# treat splitter df as multilabel class signature, so we can easy split original df to train and test\n",
    "train, test, _, ls = train_test_split(df, splitter, shuffle=True,\n",
    "                            test_size=0.15, random_state=12)\n",
    "\n",
    "# And then split test to final test and val dfs\n",
    "test, val, _, _ = train_test_split(test, ls, shuffle=True,\n",
    "                            test_size=0.33, random_state=17)\n",
    "\n",
    "train_counts = counts_to_df(train, 'description')\n",
    "test_counts = counts_to_df(test, 'description')\n",
    "val_counts = counts_to_df(val, 'description')\n",
    "\n",
    "print('Sets differences between presented symbols in train, test and val data\\n')\n",
    "\n",
    "print('train_counts - test_counts:   ', set(train_counts.symbols) - set(test_counts.symbols))\n",
    "print('train_counts - val_counts:   ', set(train_counts.symbols) - set(val_counts.symbols))\n",
    "\n",
    "print('test_counts - train_counts:   ', set(test_counts.symbols) - set(train_counts.symbols))\n",
    "print('test_counts - val_counts:   ', set(test_counts.symbols) - set(val_counts.symbols))\n",
    "\n",
    "print('val_counts - train_counts:   ', set(val_counts.symbols) - set(train_counts.symbols))\n",
    "print('val_counts - test_counts:   ', set(val_counts.symbols) - set(test_counts.symbols))\n",
    "\n",
    "# Plot frequencies of symbols in three new dataframes\n",
    "fig, axes = subplots(3, 1, figsize=(15, 15))\n",
    "\n",
    "for tmp, ax, name in zip((train_counts, test_counts, val_counts), axes, ['train', 'test', 'val']):\n",
    "    sns.barplot(data=tmp.sort_values('counts', ascending=False),\n",
    "                x='symbols', y='counts', ax=ax)\n",
    "    ax.set_title(name)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3832632-7fee-4b97-8eb5-1bafe78b42fc",
   "metadata": {},
   "source": [
    "### As we see, all symbols, except \"(\" and \")\" (they occur in dataset only 2 and 1 times respectively), are presented in all three dataframes and frequencies of symbols are very close too. Is it good or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaabe72-8411-4e49-b34a-d1f2ce71d979",
   "metadata": {},
   "source": [
    "# Making tf Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef90712-9092-4ae9-a2d9-0f2201e5af43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a87201-41cd-46e7-b0d5-e1b05595d0ac",
   "metadata": {},
   "source": [
    "### Creating mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a369a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mapping characters to integers\n",
    "counts = counts_to_df(df)\n",
    "counts = counts[~counts.isin(['', ' '])].symbols.unique().tolist() + [' ', '#']\n",
    "vocab = pd.Series(counts).str.encode('utf8')\n",
    "\n",
    "char_to_num = layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary=vocab,\n",
    "    mask_token=None,\n",
    ")\n",
    "\n",
    "# Mapping integers back to original characters\n",
    "num_to_char = layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True,\n",
    ")\n",
    "\n",
    "blank_index = char_to_num(tf.strings.unicode_split('#', input_encoding=\"UTF-8\")).numpy()[0]\n",
    "blank_index  # For oov symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6015c523-b31e-471b-be4f-a17ba304f5ae",
   "metadata": {},
   "source": [
    "### Functions for tf datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76acdde7-0727-4347-86ca-dd04fb7391e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def encode_single_sample(img_path, label):\n",
    "    \n",
    "    \"\"\"Function for processing one image from tf dataset\"\"\"\n",
    "    \n",
    "    # 1. Read \n",
    "    img = tf.io.read_file(img_path)\n",
    "    \n",
    "    # 2. Decode and convert to grayscale\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    \n",
    "    # 3. Convert to float32 in [0, 1] range\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    \n",
    "    # 4. Resize to the desired size\n",
    "    img = 1 - img\n",
    "    img = tf.image.resize_with_crop_or_pad(img, np.int32(img_height), np.int32(img_width))\n",
    "    img = 0.5 - img\n",
    "\n",
    "    # 5. Transpose the image because we want the time\n",
    "    # dimension to correspond to the width of the image.\n",
    "    img = tf.transpose(img, perm=[1, 0, 2])\n",
    "    \n",
    "    # 6. Map the characters in label to numbers\n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    label = tf.pad(label, [[0, max_length-len(label)]], constant_values=blank_index)\n",
    "    \n",
    "    # 7. Return a dict as our model is expecting two inputs\n",
    "    return {\"image\": img, \"label\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b8f05-b58d-4d6c-bc59-9ff42d51131c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(samples: pd.DataFrame, batch_size=batch_size, \n",
    "                shuffle_buffer:int=1024, prefetch:int=tf.data.experimental.AUTOTUNE) -> tf.data.Dataset:\n",
    "    \n",
    "    \"\"\"Function for creating tf dataset\"\"\"\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (samples.index.to_series().apply(lambda x: os.path.join(img_path, x) + '.jpg').tolist(),\n",
    "         samples.description.tolist())\n",
    "    )\n",
    "    \n",
    "    dataset = (\n",
    "        dataset.map(\n",
    "        encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "        )\n",
    "        .batch(batch_size)\n",
    "        .prefetch(prefetch)\n",
    "    )\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ab9ee-4e0e-4615-8bf6-37b7bde1109d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_batch(batch, batch_size):\n",
    "    \n",
    "    \"\"\"Utility function for imshow batch\"\"\"\n",
    "\n",
    "    _, ax = plt.subplots(batch_size, 1, figsize=(10, batch_size * 2))\n",
    "    images = batch['image']\n",
    "    labels = batch['label']\n",
    "    for i in range(batch_size):\n",
    "        img = ((images[i] + 0.5) * 255).numpy().astype('uint8')\n",
    "        label = tf.strings.reduce_join(num_to_char(labels[i])).numpy().decode('utf-8').replace('#', '')\n",
    "    \n",
    "        ax[i].imshow(img[i:, :, 0].T, cmap='gray')\n",
    "        ax[i].set_title(label)\n",
    "    tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051de445-2f46-4496-8f69-08b8f57bf139",
   "metadata": {},
   "source": [
    "### One batch from tf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee287ce2-e05d-4365-aa5b-502ebcb2caa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ind = df.index.tolist()\n",
    "# random.shuffle(ind)\n",
    "ls = get_dataset(df.loc[ind].iloc[:16])\n",
    "for batch in ls.take(1):\n",
    "    show_batch(batch, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb528e",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85450099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "paths = df.index.to_series().apply(lambda x: os.path.join(img_path, x) + '.jpg')\n",
    "\n",
    "aug_1 = os.path.join(img_path, 'aug_1')\n",
    "\n",
    "if not os.path.exists(aug_1):\n",
    "    os.mkdir(aug_1)\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "\n",
    "        iaa.Sometimes(0.1, iaa.GaussianBlur(3.0)),\n",
    "    \n",
    "        iaa.Sometimes(0.1, iaa.AveragePooling(2)),\n",
    "        iaa.Sometimes(0.1, iaa.Emboss(alpha=(0.0, 1.0), strength=(0.75, 1.25))),\n",
    "        iaa.Sometimes(0.1, iaa.GammaContrast((0.5, 1.0))),\n",
    "        iaa.Invert(0.05, per_channel=True),\n",
    "        iaa.Sometimes(0.1, iaa.CoarseDropout((0.0, 0.05), size_percent=(0.02, 0.25))),\n",
    "\n",
    "        iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25),\n",
    "\n",
    "        iaa.PerspectiveTransform(scale=(0.02, 0.05)),\n",
    "\n",
    "        iaa.Sometimes(0.1, iaa.SaltAndPepper(0.05)),\n",
    "    ],\n",
    "    random_order=True\n",
    ")\n",
    "\n",
    "for path in tqdm(paths):\n",
    "    break\n",
    "    print('start')\n",
    "    img = imageio.imread(path)\n",
    "    image = [np.copy(img) for _ in range(30)]\n",
    "\n",
    "    ls = seq(images=image)\n",
    "    \n",
    "    print(len(ls))\n",
    "    for i in range(30):\n",
    "        _, name = os.path.split(path)\n",
    "        name = os.path.join(aug_1, f'{i}_aug_' + name)\n",
    "        cv2.imwrite(name, ls[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa4804",
   "metadata": {},
   "source": [
    "# Preprocess module default use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fabf30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "\n",
    "img_width = 600\n",
    "\n",
    "img_height = 100\n",
    "\n",
    "# default paths\n",
    "WORKING_DIR = os.path.join('/home', 'mts')\n",
    "ann_path = os.path.join(WORKING_DIR, 'HKR_Dataset_Words_Public', 'ann')\n",
    "img_path = os.path.join(WORKING_DIR, 'HKR_Dataset_Words_Public', 'img')\n",
    "\n",
    "# collect metadata\n",
    "meta_collect(ann_path, os.path.join(WORKING_DIR, 'metadata', 'metadata.tsv'))\n",
    "\n",
    "# get preprocessed metadata dataframe\n",
    "df = PreprocessFrame(metadata=os.path.join(WORKING_DIR, 'metadata', 'metadata.tsv'),\n",
    "                     img_height=img_height, img_width=img_width)\n",
    "print(df.shape)\n",
    "\n",
    "# Make augments file (if they exists: comment or delete line)\n",
    "aug_df = None\n",
    "aug_df = make_augments(df=df, img_path=img_path, WORKING_DIR=WORKING_DIR,\n",
    "                        img_height=img_height, img_width=img_width)\n",
    "\n",
    "# get augments metadata dataframe from original dataframe if not starting make_augments\n",
    "if not isinstance(aug_df, pd.DataFrame):\n",
    "    aug_df = df.copy()\n",
    "    aug_df.index = aug_df.index.to_series().apply(lambda x: os.path.join('aug_1', 'aug_' + x))\n",
    "\n",
    "train, test, val = list(Dataset(df, aug_df=aug_df,\n",
    "                                test_size=0.1,\n",
    "                                val_size=0.05,\n",
    "                                img_path=img_path,\n",
    "                                img_height=img_height,\n",
    "                                img_width=img_width,\n",
    "                                WORKING_DIR=WORKING_DIR,\n",
    "                                shuffle=True,\n",
    "                                random_state=12))\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aac5f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in train.take(1):\n",
    "    show_batch(batch, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02eab63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in test.take(1):\n",
    "    show_batch(batch, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e6cc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in val.take(1):\n",
    "    show_batch(batch, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
